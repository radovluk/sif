{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting influxdb_client\n",
      "  Using cached influxdb_client-1.48.0-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting reactivex>=4.0.4 (from influxdb_client)\n",
      "  Using cached reactivex-4.0.4-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from influxdb_client) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from influxdb_client) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from influxdb_client) (69.5.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from influxdb_client) (2.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/lukas/miniconda3/envs/i2dl/lib/python3.11/site-packages (from reactivex>=4.0.4->influxdb_client) (4.10.0)\n",
      "Using cached influxdb_client-1.48.0-py3-none-any.whl (746 kB)\n",
      "Using cached reactivex-4.0.4-py3-none-any.whl (217 kB)\n",
      "Installing collected packages: reactivex, influxdb_client\n",
      "Successfully installed influxdb_client-1.48.0 reactivex-4.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install influxdb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/lukas/i2dl/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lukas/i2dl/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/lukas/i2dl/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiException",
     "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json; charset=utf-8', 'Vary': 'Accept-Encoding', 'X-Influxdb-Build': 'OSS', 'X-Influxdb-Version': 'v2.7.11', 'X-Platform-Error-Code': 'invalid', 'Date': 'Thu, 02 Jan 2025 10:41:32 GMT', 'Transfer-Encoding': 'chunked'})\nHTTP response body: b'{\"code\":\"invalid\",\"message\":\"error calling function \\\\\"range\\\\\" @3:16-3:49: value is not a time, got string\"}'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 209\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_sensor_data\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Fetch data for the last 24 hours, with a 24-hour interval (i.e., up to now)\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m sensor_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_all_sensor_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m sensor_data_df \u001b[38;5;241m=\u001b[39m prepare_data_for_model(sensor_data)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mprint\u001b[39m(sensor_data_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m))\n",
      "Cell \u001b[0;32mIn[6], line 185\u001b[0m, in \u001b[0;36mfetch_all_sensor_data\u001b[0;34m(start_hours, interval_hours)\u001b[0m\n\u001b[1;32m    182\u001b[0m all_sensor_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Fetch PIR sensor data\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m pir_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data_from_buckets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIR_BUCKETS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeasurement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPIR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroomID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust fields as necessary\u001b[39;49;00m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_hours\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval_hours\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m all_sensor_data\u001b[38;5;241m.\u001b[39mextend(pir_data)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Fetch Magnetic Switch data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 162\u001b[0m, in \u001b[0;36mfetch_data_from_buckets\u001b[0;34m(buckets, measurement, fields, start_hours, interval_hours)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bucket \u001b[38;5;129;01min\u001b[39;00m buckets:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[1;32m    161\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 162\u001b[0m             \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmeasurement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeasurement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfield\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_hours\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43minterval_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval_hours\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_data\n",
      "Cell \u001b[0;32mIn[6], line 87\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(bucket, measurement, field, start_hours, interval_hours)\u001b[0m\n\u001b[1;32m     74\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_start\u001b[39m\u001b[38;5;124m\"\u001b[39m: _start\u001b[38;5;241m.\u001b[39misoformat(),\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_stop\u001b[39m\u001b[38;5;124m\"\u001b[39m: _stop\u001b[38;5;241m.\u001b[39misoformat()\n\u001b[1;32m     77\u001b[0m }\n\u001b[1;32m     79\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124m    from(bucket: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124m    |> range(start: _start, stop: _stop)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124m    |> filter(fn: (r) => r[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_field\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m] == \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m---> 87\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mquery_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/client/query_api.py:203\u001b[0m, in \u001b[0;36mQueryApi.query\u001b[0;34m(self, query, org, params)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute synchronous Flux query and return result as a :class:`~influxdb_client.client.flux_table.FluxTable` list.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m:param query: the Flux query\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    ]\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    201\u001b[0m org \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_org_param(org)\n\u001b[0;32m--> 203\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_dialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_tables(response, query_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_query_options())\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/service/query_service.py:285\u001b[0m, in \u001b[0;36mQueryService.post_query\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_query_with_http_info(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     (data) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_query_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/service/query_service.py:311\u001b[0m, in \u001b[0;36mQueryService.post_query_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query data.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03mRetrieves data from buckets.  Use this endpoint to send a Flux query request and retrieve data from a bucket.  #### Rate limits (with InfluxDB Cloud)  `read` rate limits apply. For more information, see [limits and adjustable quotas](https://docs.influxdata.com/influxdb/cloud/account-management/limits/).  #### Related guides  - [Query with the InfluxDB API](https://docs.influxdata.com/influxdb/latest/query-data/execute-queries/influx-api/) - [Get started with Flux](https://docs.influxdata.com/flux/v0.x/get-started/)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m         returns the request thread.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    308\u001b[0m local_var_params, path_params, query_params, header_params, body_params \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_query_prepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/v2/query\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlopen_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murlopen_kw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/_sync/api_client.py:343\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, urlopen_kw)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make the HTTP request (synchronous) and Return deserialized data.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murlopen_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    351\u001b[0m                                    method, path_params, query_params,\n\u001b[1;32m    352\u001b[0m                                    header_params, body,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                    collection_formats,\n\u001b[1;32m    357\u001b[0m                                    _preload_content, _request_timeout, urlopen_kw))\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/_sync/api_client.py:173\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, urlopen_kw)\u001b[0m\n\u001b[1;32m    170\u001b[0m urlopen_kw \u001b[38;5;241m=\u001b[39m urlopen_kw \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    181\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/_sync/api_client.py:388\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    380\u001b[0m                                     query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    381\u001b[0m                                     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m                                     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    386\u001b[0m                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(url,\n\u001b[1;32m    398\u001b[0m                                 query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    399\u001b[0m                                 headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m                                 body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    404\u001b[0m                                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw)\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/_sync/rest.py:311\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, post_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m          body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw):\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform POST HTTP request.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl/lib/python3.11/site-packages/influxdb_client/_sync/rest.py:261\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout, **urlopen_kw)\u001b[0m\n\u001b[1;32m    258\u001b[0m     _BaseRESTClient\u001b[38;5;241m.\u001b[39mlog_body(r\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<<<\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json; charset=utf-8', 'Vary': 'Accept-Encoding', 'X-Influxdb-Build': 'OSS', 'X-Influxdb-Version': 'v2.7.11', 'X-Platform-Error-Code': 'invalid', 'Date': 'Thu, 02 Jan 2025 10:41:32 GMT', 'Transfer-Encoding': 'chunked'})\nHTTP response body: b'{\"code\":\"invalid\",\"message\":\"error calling function \\\\\"range\\\\\" @3:16-3:49: value is not a time, got string\"}'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from influxdb_client import InfluxDBClient\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Influx configuration\n",
    "INFLUX_ORG = \"wise2024\"\n",
    "# INFLUX_TOKEN = os.environ.get(\"INFLUXDB_HOST\", \"131.159.85.125:8086\")\n",
    "INFLUX_TOKEN = os.environ.get(\"INFLUXDB_HOST\", \"192.168.81.143:8086\")  # home IP\n",
    "INFLUX_USER = os.environ.get(\"INFLUXDB_USER\", \"admin\")\n",
    "INFLUX_PASS = os.environ.get(\"INFLUXDB_PASS\", \"secure_influx_iot_user\")\n",
    "\n",
    "# Sensor information\n",
    "SENSOR_MAP = {\n",
    "    \"kitchen\": {\n",
    "        \"battery\": \"1_5_10\", \n",
    "        \"PIR\": \"1_5_9\"\n",
    "    },\n",
    "    \"livingroom\": {\n",
    "        \"PIR\": \"1_4_7\",\n",
    "        \"battery\": \"1_4_8\",\n",
    "        \"magnetic_switch\": \"1_4_11\"\n",
    "    },\n",
    "    \"bathroom\": {\n",
    "        \"PIR\": \"1_3_6\",\n",
    "        \"battery\": \"1_3_5\"\n",
    "    }\n",
    "}\n",
    "\n",
    "BUCKET_DICT = {\n",
    "    \"1_5_10\": [\"kitchen_battery\"],\n",
    "    \"1_5_9\": [\"kitchen_PIR\"],\n",
    "    \"1_4_7\": [\"livingroom_PIR\"],\n",
    "    \"1_4_8\": [\"livingroom_battery\"],\n",
    "    \"1_4_11\": [\"livingroom_magnetic_switch\"],\n",
    "    \"1_3_6\": [\"bathroom_PIR\"],\n",
    "    \"1_3_5\": [\"bathroom_battery\"]\n",
    "}\n",
    "\n",
    "BUCKETS = [\"1_5_10\", \"1_5_9\", \"1_4_7\", \"1_4_8\", \"1_4_11\", \"1_3_6\", \"1_3_5\"]\n",
    "PIR_BUCKETS = [\"1_5_9\", \"1_4_7\", \"1_3_6\"]\n",
    "MAGNETIC_SWITCH_BUCKETS = [\"1_4_11\"]\n",
    "BATTERY_BUCKETS = [\"1_5_10\", \"1_4_8\"]\n",
    "\n",
    "\n",
    "def fetch_data(bucket: str,\n",
    "               measurement: str,\n",
    "               field: str,\n",
    "               start_hours: int = 24,\n",
    "               interval_hours: int = 6) -> list:\n",
    "    \"\"\"\n",
    "    Fetch data from InfluxDB starting from `start_hours` in the past \n",
    "    and spanning `interval_hours` hours forward.\n",
    "\n",
    "    Example:\n",
    "        start_hours=24, interval_hours=6\n",
    "        This will fetch data from 24 hours ago up until 18 hours ago (24 - 6).\n",
    "    \"\"\"\n",
    "    now = datetime.utcnow()\n",
    "    _start = now - timedelta(hours=start_hours)\n",
    "    _stop = _start + timedelta(hours=interval_hours)\n",
    "\n",
    "    with InfluxDBClient(\n",
    "        url=INFLUX_TOKEN,\n",
    "        org=INFLUX_ORG,\n",
    "        username=INFLUX_USER,\n",
    "        password=INFLUX_PASS,\n",
    "        verify_ssl=False\n",
    "    ) as client:\n",
    "        query_api = client.query_api()\n",
    "\n",
    "        params = {\n",
    "            \"_start\": _start.isoformat(),\n",
    "            \"_stop\": _stop.isoformat()\n",
    "        }\n",
    "\n",
    "        query = f'''\n",
    "            from(bucket: \"{bucket}\")\n",
    "            |> range(start: _start, stop: _stop)\n",
    "            |> filter(fn: (r) => r[\"_measurement\"] == \"{measurement}\")\n",
    "            |> filter(fn: (r) => r[\"_type\"] == \"sensor-value\")\n",
    "            |> filter(fn: (r) => r[\"_field\"] == \"{field}\")\n",
    "        '''\n",
    "\n",
    "        tables = query_api.query(query, params=params)\n",
    "\n",
    "        results = []\n",
    "        for table in tables:\n",
    "            for record in table.records:\n",
    "                val = {\n",
    "                    \"sensor\": BUCKET_DICT[bucket],\n",
    "                    \"bucket\": bucket,\n",
    "                    \"timestamp\": record[\"_time\"].timestamp() * 1000,\n",
    "                    \"value\": record[\"_value\"]\n",
    "                }\n",
    "\n",
    "                if bucket in BATTERY_BUCKETS:\n",
    "                    val[\"field\"] = record[\"_field\"]\n",
    "                    val[\"type\"] = \"battery\"\n",
    "                else:\n",
    "                    val[\"type\"] = \"sensor\"\n",
    "\n",
    "                results.append(val)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "def prepare_data_for_model(sensor_data: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare sensor data for model training.\n",
    "\n",
    "    :param sensor_data: List of sensor-data dictionaries.\n",
    "    :return: Preprocessed pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(sensor_data)\n",
    "\n",
    "    # Handle cases where 'sensor' is a list by extracting the first element\n",
    "    if 'sensor' in df.columns:\n",
    "        df['sensor'] = df['sensor'].apply(\n",
    "            lambda x: x[0] if isinstance(x, list) and len(x) > 0 else 'unknown_sensor'\n",
    "        )\n",
    "\n",
    "    # Convert timestamp from milliseconds to datetime\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "\n",
    "    # Sort by timestamp\n",
    "    df = df.sort_values('timestamp')\n",
    "\n",
    "    # Encode categorical variables\n",
    "    if 'sensor' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        try:\n",
    "            df['sensor_encoded'] = le.fit_transform(df['sensor'])\n",
    "        except Exception:\n",
    "            df['sensor_encoded'] = 0  # Fallback if something goes wrong\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_data_from_buckets(buckets: list,\n",
    "                            measurement: str,\n",
    "                            fields: list,\n",
    "                            start_hours: int = 24,\n",
    "                            interval_hours: int = 6) -> list:\n",
    "    \"\"\"\n",
    "    Fetch data from multiple buckets for a given measurement and fields.\n",
    "\n",
    "    :param buckets: List of bucket names.\n",
    "    :param measurement: Measurement name (e.g., \"PIR\", \"battery\").\n",
    "    :param fields: List of field names (e.g., [\"roomID\", \"soc\", \"voltage\"]).\n",
    "    :param start_hours: How many hours in the past to start.\n",
    "    :param interval_hours: Span in hours to fetch data.\n",
    "    :return: Concatenated list of data from all buckets/fields.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for bucket in buckets:\n",
    "        for field in fields:\n",
    "            all_data.extend(\n",
    "                fetch_data(\n",
    "                    bucket=bucket,\n",
    "                    measurement=measurement,\n",
    "                    field=field,\n",
    "                    start_hours=start_hours,\n",
    "                    interval_hours=interval_hours\n",
    "                )\n",
    "            )\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def fetch_all_sensor_data(start_hours: int = 24,\n",
    "                          interval_hours: int = 24) -> list:\n",
    "    \"\"\"\n",
    "    Fetch all sensor data (PIR and Magnetic Switch) within the specified time range.\n",
    "\n",
    "    :param start_hours: How many hours in the past to start fetching data.\n",
    "    :param interval_hours: Time-span (in hours) to fetch data from the start point.\n",
    "    :return: Aggregated list of sensor data.\n",
    "    \"\"\"\n",
    "    all_sensor_data = []\n",
    "\n",
    "    # Fetch PIR sensor data\n",
    "    pir_data = fetch_data_from_buckets(\n",
    "        buckets=PIR_BUCKETS,\n",
    "        measurement=\"PIR\",\n",
    "        fields=[\"roomID\"],  # Adjust fields as necessary\n",
    "        start_hours=start_hours,\n",
    "        interval_hours=interval_hours\n",
    "    )\n",
    "    all_sensor_data.extend(pir_data)\n",
    "\n",
    "    # Fetch Magnetic Switch data\n",
    "    magnetic_switch_data = fetch_data_from_buckets(\n",
    "        buckets=MAGNETIC_SWITCH_BUCKETS,\n",
    "        measurement=\"MagneticSwitch\",\n",
    "        fields=[\"roomID\"],  # Adjust fields as necessary\n",
    "        start_hours=start_hours,\n",
    "        interval_hours=interval_hours\n",
    "    )\n",
    "    all_sensor_data.extend(magnetic_switch_data)\n",
    "\n",
    "    return all_sensor_data\n",
    "\n",
    "\n",
    "\n",
    "# Fetch data for the last 24 hours, with a 24-hour interval (i.e., up to now)\n",
    "sensor_data = fetch_all_sensor_data(start_hours=24, interval_hours=24)\n",
    "sensor_data_df = prepare_data_for_model(sensor_data)\n",
    "\n",
    "print(sensor_data_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv\n",
    "df = pd.read_csv(\"data.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# parse time stamps\n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Create a flag that indicates when the 'value' changes compared to the previous row\n",
    "df['room_change'] = (df['value'] != df['value'].shift(1)).astype(int)\n",
    "\n",
    "# Create a cumulative sum of the 'room_change' flag to assign a unique group ID to each consecutive block\n",
    "df['group_id'] = df['room_change'].cumsum()\n",
    "\n",
    "# Group by 'group_id' and 'value' to handle each room separately\n",
    "duration_df = df.groupby(['group_id', 'value']).agg(\n",
    "    start_time=('timestamp', 'min'),\n",
    "    end_time=('timestamp', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate duration as the difference between end_time and start_time\n",
    "duration_df['duration'] = duration_df['end_time'] - duration_df['start_time']\n",
    "\n",
    "# Convert 'duration' to total seconds for easier numerical processing\n",
    "duration_df['duration_seconds'] = duration_df['duration'].apply(lambda x: pd.to_timedelta(x).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>value</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>700</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>2024-12-04 06:01:07.037</td>\n",
       "      <td>2024-12-04 06:10:10.375</td>\n",
       "      <td>0 days 00:09:03.338000</td>\n",
       "      <td>543.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>701</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 06:10:54.000</td>\n",
       "      <td>2024-12-04 06:10:54.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>702</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>2024-12-04 06:12:57.410</td>\n",
       "      <td>2024-12-04 06:14:26.732</td>\n",
       "      <td>0 days 00:01:29.322000</td>\n",
       "      <td>89.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>703</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 07:22:04.976</td>\n",
       "      <td>2024-12-04 07:25:12.427</td>\n",
       "      <td>0 days 00:03:07.451000</td>\n",
       "      <td>187.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>704</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 08:15:41.000</td>\n",
       "      <td>2024-12-04 08:15:41.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>705</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 08:23:59.080</td>\n",
       "      <td>2024-12-04 08:24:13.803</td>\n",
       "      <td>0 days 00:00:14.723000</td>\n",
       "      <td>14.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>706</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>2024-12-04 08:24:31.237</td>\n",
       "      <td>2024-12-04 08:33:21.808</td>\n",
       "      <td>0 days 00:08:50.571000</td>\n",
       "      <td>530.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 08:33:28.532</td>\n",
       "      <td>2024-12-04 08:34:02.072</td>\n",
       "      <td>0 days 00:00:33.540000</td>\n",
       "      <td>33.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>708</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>2024-12-04 08:34:12.971</td>\n",
       "      <td>2024-12-04 08:40:41.126</td>\n",
       "      <td>0 days 00:06:28.155000</td>\n",
       "      <td>388.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 08:52:39.603</td>\n",
       "      <td>2024-12-04 09:27:19.734</td>\n",
       "      <td>0 days 00:34:40.131000</td>\n",
       "      <td>2080.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 09:27:38.000</td>\n",
       "      <td>2024-12-04 09:27:38.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 09:29:41.748</td>\n",
       "      <td>2024-12-04 09:29:41.748</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>712</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 09:33:22.000</td>\n",
       "      <td>2024-12-04 09:33:22.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>713</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 09:38:49.433</td>\n",
       "      <td>2024-12-04 09:39:28.449</td>\n",
       "      <td>0 days 00:00:39.016000</td>\n",
       "      <td>39.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>714</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 09:44:19.000</td>\n",
       "      <td>2024-12-04 09:44:19.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>715</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 09:46:18.493</td>\n",
       "      <td>2024-12-04 09:46:18.493</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>716</td>\n",
       "      <td>livingroomdoor</td>\n",
       "      <td>2024-12-04 10:04:25.000</td>\n",
       "      <td>2024-12-04 10:04:25.000</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>717</td>\n",
       "      <td>livingroombedarea</td>\n",
       "      <td>2024-12-04 10:36:31.623</td>\n",
       "      <td>2024-12-04 10:37:01.531</td>\n",
       "      <td>0 days 00:00:29.908000</td>\n",
       "      <td>29.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>718</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>2024-12-04 10:37:43.301</td>\n",
       "      <td>2024-12-04 10:45:54.819</td>\n",
       "      <td>0 days 00:08:11.518000</td>\n",
       "      <td>491.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>2024-12-04 11:08:59.438</td>\n",
       "      <td>2024-12-04 11:09:15.344</td>\n",
       "      <td>0 days 00:00:15.906000</td>\n",
       "      <td>15.906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group_id              value              start_time  \\\n",
       "699       700           bathroom 2024-12-04 06:01:07.037   \n",
       "700       701     livingroomdoor 2024-12-04 06:10:54.000   \n",
       "701       702           bathroom 2024-12-04 06:12:57.410   \n",
       "702       703  livingroombedarea 2024-12-04 07:22:04.976   \n",
       "703       704     livingroomdoor 2024-12-04 08:15:41.000   \n",
       "704       705  livingroombedarea 2024-12-04 08:23:59.080   \n",
       "705       706           bathroom 2024-12-04 08:24:31.237   \n",
       "706       707  livingroombedarea 2024-12-04 08:33:28.532   \n",
       "707       708           bathroom 2024-12-04 08:34:12.971   \n",
       "708       709  livingroombedarea 2024-12-04 08:52:39.603   \n",
       "709       710     livingroomdoor 2024-12-04 09:27:38.000   \n",
       "710       711  livingroombedarea 2024-12-04 09:29:41.748   \n",
       "711       712     livingroomdoor 2024-12-04 09:33:22.000   \n",
       "712       713  livingroombedarea 2024-12-04 09:38:49.433   \n",
       "713       714     livingroomdoor 2024-12-04 09:44:19.000   \n",
       "714       715  livingroombedarea 2024-12-04 09:46:18.493   \n",
       "715       716     livingroomdoor 2024-12-04 10:04:25.000   \n",
       "716       717  livingroombedarea 2024-12-04 10:36:31.623   \n",
       "717       718            kitchen 2024-12-04 10:37:43.301   \n",
       "718       719           bathroom 2024-12-04 11:08:59.438   \n",
       "\n",
       "                   end_time               duration  duration_seconds  \n",
       "699 2024-12-04 06:10:10.375 0 days 00:09:03.338000           543.338  \n",
       "700 2024-12-04 06:10:54.000        0 days 00:00:00             0.000  \n",
       "701 2024-12-04 06:14:26.732 0 days 00:01:29.322000            89.322  \n",
       "702 2024-12-04 07:25:12.427 0 days 00:03:07.451000           187.451  \n",
       "703 2024-12-04 08:15:41.000        0 days 00:00:00             0.000  \n",
       "704 2024-12-04 08:24:13.803 0 days 00:00:14.723000            14.723  \n",
       "705 2024-12-04 08:33:21.808 0 days 00:08:50.571000           530.571  \n",
       "706 2024-12-04 08:34:02.072 0 days 00:00:33.540000            33.540  \n",
       "707 2024-12-04 08:40:41.126 0 days 00:06:28.155000           388.155  \n",
       "708 2024-12-04 09:27:19.734 0 days 00:34:40.131000          2080.131  \n",
       "709 2024-12-04 09:27:38.000        0 days 00:00:00             0.000  \n",
       "710 2024-12-04 09:29:41.748        0 days 00:00:00             0.000  \n",
       "711 2024-12-04 09:33:22.000        0 days 00:00:00             0.000  \n",
       "712 2024-12-04 09:39:28.449 0 days 00:00:39.016000            39.016  \n",
       "713 2024-12-04 09:44:19.000        0 days 00:00:00             0.000  \n",
       "714 2024-12-04 09:46:18.493        0 days 00:00:00             0.000  \n",
       "715 2024-12-04 10:04:25.000        0 days 00:00:00             0.000  \n",
       "716 2024-12-04 10:37:01.531 0 days 00:00:29.908000            29.908  \n",
       "717 2024-12-04 10:45:54.819 0 days 00:08:11.518000           491.518  \n",
       "718 2024-12-04 11:09:15.344 0 days 00:00:15.906000            15.906  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Room Statistics:\n",
      "               value         mean          std\n",
      "0           bathroom   335.878195  1632.663384\n",
      "1            kitchen  1094.701454  4613.714474\n",
      "2  livingroombedarea  1411.446180  5113.371932\n",
      "3     livingroomdoor   166.646465   563.477420\n"
     ]
    }
   ],
   "source": [
    "# Group by 'value' (room) and calculate statistics\n",
    "room_stats = duration_df.groupby('value')['duration_seconds'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Handle cases where std might be NaN (e.g., only one entry for a room)\n",
    "room_stats['std'] = room_stats['std'].fillna(0)\n",
    "\n",
    "print(\"\\nRoom Statistics:\")\n",
    "print(room_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusted Room Statistics with Bounds:\n",
      "               value         mean          std   upper_bound  lower_bound\n",
      "0           bathroom   335.878195  1632.663384   5233.868348            0\n",
      "1            kitchen  1094.701454  4613.714474  14935.844876            0\n",
      "2  livingroombedarea  1411.446180  5113.371932  16751.561975            0\n",
      "3     livingroomdoor   166.646465   563.477420   1857.078723            0\n"
     ]
    }
   ],
   "source": [
    "# Define anomaly threshold (e.g., 3 standard deviations)\n",
    "threshold = 3\n",
    "\n",
    "# Calculate upper and lower bounds for each room\n",
    "room_stats['upper_bound'] = room_stats['mean'] + threshold * room_stats['std']\n",
    "room_stats['lower_bound'] = room_stats['mean'] - threshold * room_stats['std']\n",
    "\n",
    "# Replace negative lower bounds with zero\n",
    "room_stats['lower_bound'] = room_stats['lower_bound'].apply(lambda x: max(x, 0))\n",
    "\n",
    "print(\"\\nAdjusted Room Statistics with Bounds:\")\n",
    "print(room_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(new_data, stats_df, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect anomalies based on the duration spent in each room.\n",
    "    \n",
    "    Parameters:\n",
    "    - new_data: DataFrame with 'value', 'start_time', 'end_time', 'duration_seconds'\n",
    "    - stats_df: DataFrame with 'value', 'mean', 'std', 'upper_bound', 'lower_bound'\n",
    "    - threshold: Number of standard deviations to use for anomaly detection\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame containing anomalies\n",
    "    \"\"\"\n",
    "    # Merge new data with statistics\n",
    "    merged = new_data.merge(stats_df, on='value', how='left')\n",
    "    \n",
    "    # Replace NaN statistics with zero bounds (assuming no prior data)\n",
    "    merged['upper_bound'] = merged['upper_bound'].fillna(0)\n",
    "    merged['lower_bound'] = merged['lower_bound'].fillna(0)\n",
    "    \n",
    "    # Identify anomalies\n",
    "    anomalies = merged[\n",
    "        (merged['duration_seconds'] > merged['upper_bound']) |\n",
    "        (merged['duration_seconds'] < merged['lower_bound'])\n",
    "    ]\n",
    "    \n",
    "    return anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomalies Detected:\n",
      "     group_id              value              start_time  \\\n",
      "3           4            kitchen 2024-11-21 02:50:16.250   \n",
      "4           5  livingroombedarea 2024-11-21 09:03:39.394   \n",
      "12         13           bathroom 2024-11-22 08:28:38.224   \n",
      "13         14            kitchen 2024-11-22 14:14:52.088   \n",
      "74         75  livingroombedarea 2024-11-23 00:49:08.798   \n",
      "129       130           bathroom 2024-11-23 17:24:45.436   \n",
      "150       151  livingroombedarea 2024-11-24 00:14:56.818   \n",
      "235       236           bathroom 2024-11-24 07:37:25.764   \n",
      "339       340            kitchen 2024-11-25 06:23:15.014   \n",
      "363       364  livingroombedarea 2024-11-26 01:47:15.327   \n",
      "368       369     livingroomdoor 2024-11-26 08:27:44.000   \n",
      "502       503            kitchen 2024-11-27 12:39:43.486   \n",
      "515       516     livingroomdoor 2024-11-27 21:03:48.000   \n",
      "540       541            kitchen 2024-11-28 12:57:08.824   \n",
      "615       616            kitchen 2024-11-30 18:29:17.050   \n",
      "639       640            kitchen 2024-12-01 12:41:45.348   \n",
      "656       657     livingroomdoor 2024-12-03 08:56:27.000   \n",
      "\n",
      "                   end_time               duration  duration_seconds  \\\n",
      "3   2024-11-21 07:01:32.415 0 days 04:11:16.165000         15076.165   \n",
      "4   2024-11-21 15:18:02.984 0 days 06:14:23.590000         22463.590   \n",
      "12  2024-11-22 12:20:39.478 0 days 03:52:01.254000         13921.254   \n",
      "13  2024-11-22 19:36:03.029 0 days 05:21:10.941000         19270.941   \n",
      "74  2024-11-23 09:44:21.108 0 days 08:55:12.310000         32112.310   \n",
      "129 2024-11-23 22:24:04.936 0 days 04:59:19.500000         17959.500   \n",
      "150 2024-11-24 06:25:33.574 0 days 06:10:36.756000         22236.756   \n",
      "235 2024-11-24 10:05:31.751 0 days 02:28:05.987000          8885.987   \n",
      "339 2024-11-25 16:50:49.279 0 days 10:27:34.265000         37654.265   \n",
      "363 2024-11-26 07:05:48.335 0 days 05:18:33.008000         19113.008   \n",
      "368 2024-11-26 09:01:14.000        0 days 00:33:30          2010.000   \n",
      "502 2024-11-27 17:30:06.616 0 days 04:50:23.130000         17423.130   \n",
      "515 2024-11-27 21:42:17.000        0 days 00:38:29          2309.000   \n",
      "540 2024-11-28 21:36:06.797 0 days 08:38:57.973000         31137.973   \n",
      "615 2024-12-01 06:17:10.423 0 days 11:47:53.373000         42473.373   \n",
      "639 2024-12-01 20:31:42.731 0 days 07:49:57.383000         28197.383   \n",
      "656 2024-12-03 10:02:50.000        0 days 01:06:23          3983.000   \n",
      "\n",
      "            mean          std   upper_bound  lower_bound  \n",
      "3    1094.701454  4613.714474  14935.844876            0  \n",
      "4    1411.446180  5113.371932  16751.561975            0  \n",
      "12    335.878195  1632.663384   5233.868348            0  \n",
      "13   1094.701454  4613.714474  14935.844876            0  \n",
      "74   1411.446180  5113.371932  16751.561975            0  \n",
      "129   335.878195  1632.663384   5233.868348            0  \n",
      "150  1411.446180  5113.371932  16751.561975            0  \n",
      "235   335.878195  1632.663384   5233.868348            0  \n",
      "339  1094.701454  4613.714474  14935.844876            0  \n",
      "363  1411.446180  5113.371932  16751.561975            0  \n",
      "368   166.646465   563.477420   1857.078723            0  \n",
      "502  1094.701454  4613.714474  14935.844876            0  \n",
      "515   166.646465   563.477420   1857.078723            0  \n",
      "540  1094.701454  4613.714474  14935.844876            0  \n",
      "615  1094.701454  4613.714474  14935.844876            0  \n",
      "639  1094.701454  4613.714474  14935.844876            0  \n",
      "656   166.646465   563.477420   1857.078723            0  \n"
     ]
    }
   ],
   "source": [
    "# Example: Detect anomalies in the existing data\n",
    "anomalies = detect_anomalies(duration_df, room_stats, threshold=3)\n",
    "\n",
    "print(\"\\nAnomalies Detected:\")\n",
    "print(anomalies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
